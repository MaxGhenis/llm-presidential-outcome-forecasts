\section{Conclusion}\label{sec:conclusion}

This study demonstrates both the potential and limitations of using language models for policy forecasting. The consistency in directional predictions across models, particularly for environmental and poverty outcomes, suggests that narrative-prompted LLMs can provide meaningful insight into potential policy impacts. However, the systematic differences between models and varying levels of prediction uncertainty highlight the importance of using multiple approaches and maintaining appropriate skepticism.

The results also provide insight into the behavior of different language models. GPT-4o-mini's consistently smaller effect sizes and Grok's larger predictions reveal systematic differences in how models extrapolate from their training data. These patterns suggest that comparing predictions across models may provide useful information about forecast uncertainty.

Future work could validate these methods against historical policy changes, explore alternative prompting strategies, and develop ways to combine LLM predictions with traditional forecasting approaches. As language models continue to evolve, their potential role in policy analysis deserves continued investigation.